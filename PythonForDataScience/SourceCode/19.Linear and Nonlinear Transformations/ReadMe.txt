Previous chapters introduced you to some of the simplest, yet effective,
machine-learning algorithms, such as linear and logistic regression,
Naïve Bayes, and K-Nearest Neighbors (KNN). At this point, you can successfully
complete a regression or classification project in data science. This chapter
explores even more complex and powerful machine-learning techniques
including the following: reasoning on how to enhance your data; controlling
the variance of estimates by regularization; and managing to learn from big
data by breaking it into manageable chunks.
This chapter also introduces you to the support vector machine (SVM), a
powerful family of algorithms for classification and regression. SVMs are
able to perform the most difficult data problems and are a perfect substitute
for neural networks such as the multilayer perceptron, which isn’t currently
present in the Scikit-learn package but is a planned addition in the future.
Given the complexity of the subject, more than half of the chapter is devoted
to SVM, but it’s definitely worth the time.