{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('Data/train_wrangled_X.csv').values\n",
    "y_train = pd.read_csv('Data/train_wrangled_y.csv').values\n",
    "X_test = pd.read_csv('Data/test_wrangled.csv').values\n",
    "y_test = pd.read_csv('Data/y_test_wrangled.csv').values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting Random Forest Classification to the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ripti\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators = 10,\n",
    "                                    criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the Test set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making the Confusion Matrix to Determine Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[241  25]\n",
      " [ 38 114]]\n",
      "Accuracy: 84.93%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print(\"Accuracy: \"+str(round((((\n",
    "    241+114)/(241+114+38+25))*100),2))+\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using a Dense Nueral Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ripti\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Model and Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=10, activation='relu'))\n",
    "model.add(Dense(10, activation='sigmoid'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit the model to the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "891/891 [==============================] - 0s - loss: 0.4269 - acc: 0.8384     \n",
      "Epoch 2/20\n",
      "891/891 [==============================] - 0s - loss: 0.4247 - acc: 0.8406     \n",
      "Epoch 3/20\n",
      "891/891 [==============================] - 0s - loss: 0.4230 - acc: 0.8440     \n",
      "Epoch 4/20\n",
      "891/891 [==============================] - 0s - loss: 0.4220 - acc: 0.8429     \n",
      "Epoch 5/20\n",
      "891/891 [==============================] - 0s - loss: 0.4216 - acc: 0.8451     \n",
      "Epoch 6/20\n",
      "891/891 [==============================] - 0s - loss: 0.4200 - acc: 0.8429     \n",
      "Epoch 7/20\n",
      "891/891 [==============================] - 0s - loss: 0.4209 - acc: 0.8406     \n",
      "Epoch 8/20\n",
      "891/891 [==============================] - 0s - loss: 0.4186 - acc: 0.8429     \n",
      "Epoch 9/20\n",
      "891/891 [==============================] - 0s - loss: 0.4188 - acc: 0.8451     \n",
      "Epoch 10/20\n",
      "891/891 [==============================] - 0s - loss: 0.4165 - acc: 0.8418     \n",
      "Epoch 11/20\n",
      "891/891 [==============================] - 0s - loss: 0.4168 - acc: 0.8474     \n",
      "Epoch 12/20\n",
      "891/891 [==============================] - 0s - loss: 0.4154 - acc: 0.8429     \n",
      "Epoch 13/20\n",
      "891/891 [==============================] - 0s - loss: 0.4149 - acc: 0.8440     \n",
      "Epoch 14/20\n",
      "891/891 [==============================] - 0s - loss: 0.4136 - acc: 0.8451     \n",
      "Epoch 15/20\n",
      "891/891 [==============================] - 0s - loss: 0.4131 - acc: 0.8440     \n",
      "Epoch 16/20\n",
      "891/891 [==============================] - 0s - loss: 0.4125 - acc: 0.8474     \n",
      "Epoch 17/20\n",
      "891/891 [==============================] - 0s - loss: 0.4117 - acc: 0.8462     \n",
      "Epoch 18/20\n",
      "891/891 [==============================] - 0s - loss: 0.4110 - acc: 0.8440     \n",
      "Epoch 19/20\n",
      "891/891 [==============================] - 0s - loss: 0.4117 - acc: 0.8451     \n",
      "Epoch 20/20\n",
      "891/891 [==============================] - 0s - loss: 0.4109 - acc: 0.8418     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d26fbff320>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=20, batch_size=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the model against the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 32/418 [=>............................] - ETA: 0s\n",
      "acc: 90.19%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test).round()\n",
    "np.savetxt(\"predictions.csv\",y_pred,delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
